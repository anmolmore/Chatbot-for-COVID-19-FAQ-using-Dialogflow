{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn_deltatfidf import DeltaTfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = pd.read_csv('knowledge_base.csv')\n",
    "covid_data = pd.DataFrame(covid_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a coronavirus\n"
     ]
    }
   ],
   "source": [
    "covid_data.columns = ['OriginalText']\n",
    "print(list(covid_data['OriginalText'])[0])\n",
    "train_x_tf = covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 407/407 [00:00<00:00, 717.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalText</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is a coronavirus</td>\n",
       "      <td>What is a coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>What kind of diseases are caused by corona virus</td>\n",
       "      <td>What kind of diseases are caused by corona virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>What is covid-19</td>\n",
       "      <td>What is covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>When does corona disease started</td>\n",
       "      <td>When does corona disease started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>what are the symptoms of covid-19</td>\n",
       "      <td>what are the symptoms of covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalText  \\\n",
       "0                             What is a coronavirus   \n",
       "1  What kind of diseases are caused by corona virus   \n",
       "2                                  What is covid-19   \n",
       "3                  When does corona disease started   \n",
       "4                 what are the symptoms of covid-19   \n",
       "\n",
       "                                        CleanedText  \n",
       "0                             What is a coronavirus  \n",
       "1  What kind of diseases are caused by corona virus  \n",
       "2                                     What is covid  \n",
       "3                  When does corona disease started  \n",
       "4                    what are the symptoms of covid  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "train_x_tf['CleanedText'] = ''\n",
    "# tqdm is for printing the status bar\n",
    "for i in tqdm(range(0,train_x_tf['OriginalText'].shape[0]-1)):\n",
    "    range(0,train_x_tf['OriginalText'].shape[0]-1)\n",
    "    sentence = str(train_x_tf.iloc[i,[train_x_tf.columns.get_loc('OriginalText')]].values)    \n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()    \n",
    "    sentence = re.sub('[<>%\\$\\'\\,\\|]', ' ', sentence)    \n",
    "    sentence = re.sub('[^a-zA-Z]',' ',train_x_tf['OriginalText'].iloc[:].values[i])  \n",
    "#    sentence = ' '.join(e for e in sentence.split() if e not in final_stopwords)    \n",
    "    train_x_tf.iloc[i,[train_x_tf.columns.get_loc('CleanedText')]] = sentence.strip()     \n",
    "train_x_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.22.2.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fvAmu91Jkk6"
   },
   "source": [
    "## TF-IDF Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ag5-WCR8Jkk7",
    "outputId": "94a8ddc3-4bb7-4c49-d4e7-ed98560633b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ STANDARDIZATION : Training ~~~~~\n",
      "Shape after standarizing: (408, 105)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Implementation\n",
    "\n",
    "#initiate TfidfVectorizer with default parameters\n",
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "#Learning the internal parameters of data before doing transform\n",
    "#Here the dimension of the vectorizer is based on xtr\n",
    "#(which will be applied to crossvalidation and test also during transform)\n",
    "tf_idf_vect = tf_idf_vectorizer.fit(train_x_tf.CleanedText)\n",
    "\n",
    "#Applying the learned parameters and creating vectorizer output (Dimension same as xtr)\n",
    "final_xtr = tf_idf_vect.transform(train_x_tf.CleanedText)\n",
    "\n",
    "with open('covid_tf_idf_vect.pkl', 'wb') as f:\n",
    "    pickle.dump(tf_idf_vect, f)\n",
    "\n",
    "\n",
    "##-----------------Standardizing --- START\n",
    "\n",
    "#Standardizing the vectorized matrix\n",
    "final_xtr_std = StandardScaler(with_mean=False)\n",
    "# here it will learn mu and sigma\n",
    "final_xtr_std.fit(final_xtr)\n",
    "\n",
    "print(\"~~~~ STANDARDIZATION : Training ~~~~~\")\n",
    "# with the learned mu and sigma it will do std on train data\n",
    "standardized_tfidf_train = final_xtr_std.transform(final_xtr)\n",
    "print('Shape after standarizing:',standardized_tfidf_train.shape)\n",
    "print(type(standardized_tfidf_train))\n",
    "\n",
    "with open('covid_final_xtr_std.pkl', 'wb') as f:\n",
    "    pickle.dump(final_xtr_std, f)\n",
    "    \n",
    "with open('covid_standardized_tfidf_train.pkl', 'wb') as f:\n",
    "    pickle.dump(standardized_tfidf_train, f)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
