summary(ridge.model)
ridge.model$kLW
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.1,0.5,0.001))
summary(ridge.model)
ridge.model$kLW
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
summary(ridge.model)
ridge.model$kLW
anova(ridge.model)
summary(ridge.model)
ridge.model$kLW
plot(ridge.model, lambda = seq(0,0.1,0.001)))
plot(ridge.model, lambda = seq(0,0.1,0.001))
wildcat <- read.csv('wildcat.csv')
View(wildcat)
wildcat <- read.csv('wildcat.csv', na.strings = c('--'))
#plot histogram for Workforce
hist(wildcat$Workforce)
#carry linear regression and check summary and anova
model <- lm(mpg ~ disp + hp + wt + qsec, data=cars)
summary(model)
anova(model)
#carry linear regression and check summary and anova
model <- lm(mpg ~ disp + hp + wt + qsec, data=cars)
summary(model)
anova(model)
#plotting each of the scatter plots separately
plot(x=cars$disp, y=cars$mpg, xlab ="disp", ylab = "mpg" )
#use mtcars dataset directly
describe(mtcars)
View(mtcars)
View(mtcars)
#plotting each of the scatter plots separately
plot(x=cars$disp, y=cars$mpg, xlab ="disp", ylab = "mpg" )
plot(x=cars$hp, y=cars$mpg, xlab ="hp", ylab = "mpg" )
plot(x=cars$wt, y=cars$mpg, xlab ="wt", ylab = "mpg" )
plot(x=cars$qsec, y=cars$mpg, xlab ="qsec", ylab = "mpg" )
car::vif(model)
#check for correlation between four regressors
cor(cars)
cat('check of vif values')
car::vif(model)
cat('check for correlation between four regressors')
cor(cars)
cat('check of vif values')
car::vif(model)
cat('\ncheck for correlation between four regressors')
cor(cars)
cat('check of vif values\n')
car::vif(model)
cat('\ncheck for correlation between four regressors\n')
cor(cars)
AIC(model)
cat('check of vif values\n')
car::vif(model)
cat('\ncheck for correlation between four regressors\n')
cor(cars)
cat('\ncheck further using AIC and BIC of model\n')
AIC(model)
BIC(model)
plot(ridge.model, lambda = seq(0,1,0.001))
plot(ridge.model, lambda = seq(0,1,0.001), xlab = 'Lambda')
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
summary(ridge.model)
summary(ridge.model)
ridge.model$kHKB
ridge.model$GCV
min(ridge.model$GCV)
which.min(ridge.model$GCV)
ridge.model$kLW
coef(ridge.model, lambda=0.47)
residuals(ridge.model)
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.47)
AIC(ridge.model)
AIC(ridge.model)
anova(ridge.model)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.0001))
names(ridge.model)
print(ridge.model$kLW)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$kLW)
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.47)
plot(ridge.model, lambda = seq(0,1,0.001))
ridge.model$kHKB
min(ridge.model$GCV)
which.min(ridge.model$GCV)
ridge.model$kLW
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.23)
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.46)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$kLW)
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.23)
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars), lambda=0.46)
#using lambda value from kHKB method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$kLW)
#using lambda value from kHKB method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
library(MASS)
library(leaps)
#use mtcars dataset directly
cars <- mtcars
#carry linear regression and check summary and anova
model <- lm(mpg ~ disp + hp + wt + qsec, data=cars)
summary(model)
anova(model)
#plotting each of the scatter plots separately
plot(x=cars$disp, y=cars$mpg, xlab ="disp", ylab = "mpg" )
plot(x=cars$hp, y=cars$mpg, xlab ="hp", ylab = "mpg" )
plot(x=cars$wt, y=cars$mpg, xlab ="wt", ylab = "mpg" )
plot(x=cars$qsec, y=cars$mpg, xlab ="qsec", ylab = "mpg" )
cat('check of vif values\n')
car::vif(model)
cat('\ncheck for correlation between four regressors\n')
cor(cars)
cat('\ncheck further using AIC and BIC of model\n')
AIC(model)
BIC(model)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
plot(ridge.model, lambda = seq(0,1,0.001))
ridge.model$kHKB
min(ridge.model$GCV)
which.min(ridge.model$GCV)
ridge.model$kLW
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#using lambda value from GCV method, we get coefficients as
min(coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23)))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#using lambda value from GCV method, we get coefficients as
min(coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23)))
#using lambda value from kLW method, we get coefficients as
min(coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46)))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
print(ridge.model$GCV)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
library(MASS)
library(leaps)
#use mtcars dataset directly
cars <- mtcars
#carry linear regression and check summary and anova
model <- lm(mpg ~ disp + hp + wt + qsec, data=cars)
summary(model)
anova(model)
#plotting each of the scatter plots separately
plot(x=cars$disp, y=cars$mpg, xlab ="disp", ylab = "mpg" )
plot(x=cars$hp, y=cars$mpg, xlab ="hp", ylab = "mpg" )
plot(x=cars$wt, y=cars$mpg, xlab ="wt", ylab = "mpg" )
plot(x=cars$qsec, y=cars$mpg, xlab ="qsec", ylab = "mpg" )
cat('check of vif values\n')
car::vif(model)
cat('\ncheck for correlation between four regressors\n')
cor(cars)
cat('\ncheck further using AIC and BIC of model\n')
AIC(model)
BIC(model)
#ridge model with lambda values from 0.01, to 1
ridge.model <- lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda = seq(0.01,1,0.001))
names(ridge.model)
#using lambda value from GCV method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.23))
#using lambda value from kLW method, we get coefficients as
coef(lm.ridge(mpg ~ disp + hp + wt + qsec, data=cars, lambda=0.46))
plot(ridge.model, lambda = seq(0,1,0.001))
ridge.model$kHKB
min(ridge.model$GCV)
which.min(ridge.model$GCV)
ridge.model$kLW
wildcat <- read.csv('wildcat.csv', na.strings = c('--'))
wildcat$Workforce <- ln(wildcat$Workforce)
ln(3)
log(3)
wildcat$Workforce <- log(wildcat$Workforce)
#transfor workforce to log
wildcat$Workforce <- log(wildcat$Workforce)
lm.model <- lm(wildcat$Wildcat.strikes~.)
lm.model <- lm(Wildcat.strikes~., data = wildcat)
summary(lm.model)
wildcat.union.data <- wildcat$Union == 1
hist(wildcat$Wildcat.strikes)
hist(wildcat$Union == 0)
wildcat[wildcat$Union == 0]
wildcat[wildcat$Union = 0]
wildcat(wildcat$Union = 0)
wildcat[wildcat$Union = 0]
wildcat[wildcat$Union == 0]
ifelse(wildcat$Union > 0)
wildcat$Union == 0;
#hist plot of wildcat strikes
wildcat$Union == 0
#hist plot of wildcat strikes
wildcat[wildcat$Union == 0]
#hist plot of wildcat strikes
wildcat[Union == 0]
#hist plot of wildcat strikes
wildcat[Wildcat$Union == 0]
#hist plot of wildcat strikes
wildcat[Wildcat$Union == 0]
#hist plot of wildcat strikes
wildcat[c(Wildcat$Union == 0)]
#hist plot of wildcat strikes
wildcat.index[Wildcat$Union == 0]
index(wildcat$Union == 0)
wildcat$Union == 0;
wildcat$wildcat$Union == 0;
temp <- wildcat$wildcat$Union == 0;
wildcat$wildcat$Union == 0;
wildcat$Union == 0;
wildcat$Union == 1;
wildcat[[wildcat$Union == 1]];
wildcat.union.data <- subset(wildcat, union > 0)
wildcat.union.data <- subset(wildcat, union == 1)
wildcat.union.data <- subset(wildcat, wildcat$union == 1)
View(wildcat.union.data)
wildcat.union.data <- subset(wildcat, wildcat$Union == 1)
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~., data = wildcat.union.data)
summary(lm.model)
lm.model <- lm(Wildcat.strikes~., data = wildcat.union.data)
summary(lm.model)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~., data = wildcat.union.data)
summary(lm.model)
lm.model <- lm(Wildcat.strikes~., data = wildcat.no.union.data)
View(wildcat.union.data)
View(wildcat.no.union.data)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce+, data = wildcat.union.data)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce+, data = wildcat.union.data)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
#seprate two kinds of data
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(lm.model)
lm.model <- lm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data)
summary(lm.model)
lm.model <- lm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data)
summary(lm.model)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
#seprate two kinds of data
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(lm.model)
nonunionized.model <- poisson(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data)
nonunionized.model <- glm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data, family=poisson)
nonunionized.model <- glm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data, family=poisson)
summary(nonunionized.model)
wildcat <- read.csv('wildcat.csv', na.strings = c('--'))
#plot histogram for Workforce
hist(wildcat$Workforce)
#transfor workforce to log
wildcat$Workforce <- log(wildcat$Workforce)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
#seprate two kinds of data
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(lm.model)
#run linear regression for no union data
lm.model <- lm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data)
summary(lm.model)
nonunionized.model <- glm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data, family=poisson)
summary(nonunionized.model)
unionized.model <- glm(Wildcat.strikes~Rotate+Workforce, data = wildcat.union.data, family=poisson)
summary(nonunionized.model)
#negative binomial model
unionized.model.nb <- glm.nb(Wildcat.strikes~Rotate+Workforce, data = wildcat.union.data)
unionized.model <- glm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data, family=poisson)
summary(nonunionized.model)
unionized.model <- glm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data, family=poisson)
summary(unionized.model)
#negative binomial model
unionized.model.nb <- glm.nb(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
library(MASS)
library(MASS)
library(AER)
#negative binomial model
unionized.model.nb <- glm.nb(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(unionized.model.nb)
unionized.model <- glm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data, family=poisson)
summary(unionized.model)
checkResiduals(unionized.model)
stm::checkResiduals(unionized.model)
hist(wildcat.union.data$Wildcat.strikes)
library(MASS)
library(AER)
wildcat <- read.csv('wildcat.csv', na.strings = c('--'))
#plot histogram for Workforce
hist(wildcat$Workforce)
#transfor workforce to log
wildcat$Workforce <- log(wildcat$Workforce)
#hist plot of wildcat strikes
hist(wildcat$Wildcat.strikes)
#seprate two kinds of data
wildcat.union.data <- subset(wildcat, Union == 1)
wildcat.no.union.data <- subset(wildcat, Union == 0)
lm.model <- lm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(lm.model)
#run linear regression for no union data
lm.model <- lm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data)
summary(lm.model)
nonunionized.model <- glm(Wildcat.strikes~Rotate+Workforce, data = wildcat.no.union.data, family=poisson)
summary(nonunionized.model)
unionized.model <- glm(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data, family=poisson)
summary(unionized.model)
hist(wildcat.union.data$Wildcat.strikes)
#look for package to check dispersion
#stm::checkResiduals(unionized.model)
#negative binomial model
unionized.model.nb <- glm.nb(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(unionized.model.nb)
anova(unionized.model.nb)
#negative binomial model
unionized.model.nb <- glm.nb(Wildcat.strikes~Grievances+Rotate+Workforce, data = wildcat.union.data)
summary(unionized.model.nb)
anova(unionized.model.nb)
#plot histogram for Workforce
hist(wildcat$Workforce)
hist(log(wildcat$Workforce))
data <- read.csv('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ .)
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ ., family=binomial())
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ ., data=data, family=binomial())
model
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ ., data=data, family=binomial())
summary(model)
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ test + imp_1 + imp_2 + imp_3 + imp_4 + imp_5 + imp_6, data=data, family=binomial())
summary(model)
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ test + imp_1 + imp_2 + imp_3 + imp_4 + imp_5 + imp_6, data=data, family=binomial())
summary(model)
size(data)
data <- readxl::read_excel('/Users/anmol/OneDrive - Indian School of Business/Github/ISB-Term3/Social Media and Web Analytics/Individual Assignment/Dataset.xls')
model <- glm(purchase ~ test + imp_1 + imp_2 + imp_3 + imp_4 + imp_5 + imp_6, data=data, family=binomial())
summary(model)
shape(data)
knitr::opts_chunk$set(echo = TRUE)
#Ref : https://www.r-bloggers.com/finding-optimal-number-of-clusters/
# https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/
#read conjoint data
data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Conjoint Data', skip=3, n_max = 317)
data_scaled = as.matrix(scale(data))
#Ref : https://www.r-bloggers.com/finding-optimal-number-of-clusters/
# https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/
#read conjoint data
data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Conjoint Data', skip=3, n_max = 317)
data_scaled = as.matrix(scale(data))
demographics_data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Demographics', skip=3, n_max = 317)
demographics_data$cluster <- kmeans(data_scaled,3)$cluster
demographics_data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Demographics', skip=3, n_max = 317)
demographics_data$cluster <- kmeans(data,3)$cluster
setwd("~/OneDrive - Indian School of Business/Github/ISB-Term3/Marketing Analytics/assignment")
knitr::opts_chunk$set(echo = TRUE)
#Ref : https://www.r-bloggers.com/finding-optimal-number-of-clusters/
# https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/
#read conjoint data
data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Conjoint Data', skip=3, n_max = 317)
data_scaled = as.matrix(scale(data))
#Ref : https://www.r-bloggers.com/finding-optimal-number-of-clusters/
# https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/
#read conjoint data
data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Conjoint Data', skip=3, n_max = 317)
data_scaled = as.matrix(scale(data))
demographics_data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Demographics', skip=3, n_max = 317)
demographics_data$cluster <- kmeans(data,3)$cluster
View(data)
#Ref : https://www.r-bloggers.com/finding-optimal-number-of-clusters/
# https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/
#read conjoint data
data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Conjoint Data', skip=13, n_max = 317)
data_scaled = as.matrix(scale(data))
View(data)
demographics_data <- readxl::read_excel('Beer Partworth Data.xls', sheet = 'Demographics', skip=3, n_max = 317)
demographics_data$cluster <- kmeans(data_scaled,3)$cluster
#data_scaled = as.matrix(scale(data))
#kmeans(data_scaled,3)$cluster
demographics_scaled_data <- as.matrix(scale(demographics_data[, -c(1)]))
View(demographics_data)
install.packages("NbClust",dependencies = TRUE)
library(NbClust)
nb <- NbClust(demographics_scaled_data, diss=NULL, distance = "euclidean",
min.nc=2, max.nc=5, method = "kmeans",
index = "all", alphaBeale = 0.1)
hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))
library(factoextra)
library(NbClust)
# Elbow method
fviz_nbclust(demographics_scaled_data, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# Silhouette method
fviz_nbclust(data_scaled, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(demographics_scaled_data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
library(useful)
wineBest <- FitKMeans(demographics_scaled_data, max.clusters=20, nstart=25)
PlotHartigan(wineBest)
demographics_data$demo_cluster <- kmeans(demographics_scaled_data, 4)$cluster
View(demographics_data)
pairs(demographics_data[,-c(1)])
write.csv(demographics_data, file = "clustering data.csv")
pairs(demographics_data[,-c(1)])
ggplot(demographics_data[,c(2,8)]) + geom_line() + facet_grid(series ~ .)
demographics_data[,c(2,8)]
demographics_data[c(2,8)]
ggplot(demographics_data[c(2,8)]) + geom_line() + facet_grid(series ~ .)
ggplot(demographics_data[c(2,8)])
ggplot(demographics_data[c(2,8)]) + geom_line()
ggplot(demographics_data[c(2,8)], aes(Weekly consumption,demo_cluster)) + geom_line()
ggplot(demographics_data[c(2,8)], aes('Weekly consumption','demo_cluster')) + geom_line()
ggplot(demographics_data[c(2,8)], aes('Weekly consumption','demo_cluster')) + geom_line() + facet_grid(series ~ .)
plot(demographics_data[c(2,8)], aes('Weekly consumption','demo_cluster')) + geom_line()
plot(demographics_data[c(2,8)], aes('Weekly consumption','demo_cluster'))
demographics_data[c(3,8)]
plot(demographics_data[c(3,8)], aes('Age','demo_cluster'))
demographics_data[c(4,8)]
plot(demographics_data[c(3,8)], aes('Income','demo_cluster'))
plot(demographics_data[c(4,8)], aes('Income','demo_cluster'))
demographics_data[c(5,8)]
plot(demographics_data[c(5,8)], aes('Education','demo_cluster'))
demographics_data[c(6,8)]
plot(demographics_data[c(6,8)], aes('Sex','demo_cluster'))
demographics_data[c(7,8)]
plot(demographics_data[c(7,8)], aes('Sex','demo_cluster'))
